{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "API_KEY = 'ei_7c14274991477b16092db6eb8032e84b9f73c9c9e665b5c8bec01333b86151f3'\n",
    "\n",
    "X = (requests.get('https://studio.edgeimpulse.com/v1/api/18137/training/6/x', headers={'x-api-key': API_KEY})).content\n",
    "Y = (requests.get('https://studio.edgeimpulse.com/v1/api/18137/training/6/y', headers={'x-api-key': API_KEY})).content\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the data in a temporary file, and load it back through Numpy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('x_train.npy', 'wb') as file:\n",
    "    file.write(X)\n",
    "with open('y_train.npy', 'wb') as file:\n",
    "    file.write(Y)\n",
    "X = np.load('x_train.npy')\n",
    "Y = np.load('y_train.npy')[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%reload_ext tensorboard\n",
    "import sys, os, random\n",
    "import tensorflow as tf\n",
    "import datetime, os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Set random seeds for repeatable results\n",
    "RANDOM_SEED = 3\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "classes_values = [ \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"N\", \"o\", \"s\" ]\n",
    "classes = len(classes_values)\n",
    "\n",
    "Y = tf.keras.utils.to_categorical(Y - 1, classes)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "\n",
    "input_length = X_train[0].shape[0]\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n",
    "\n",
    "logdir = os.path.join(\"./logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def set_batch_size(batch_size, train_dataset, validation_dataset):\n",
    "    train_dataset = train_dataset.batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    validation_dataset = validation_dataset.batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return train_dataset, validation_dataset\n",
    "\n",
    "\n",
    "import io\n",
    "def plot_to_image(figure):\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "\n",
    "    digit = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    digit = tf.expand_dims(digit, 0)\n",
    "\n",
    "    return digit\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names):\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Accent)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "    threshold = cm.max() / 2.\n",
    "\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    return figure\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn import metrics\n",
    "\n",
    "def log_confusion_matrix(epoch, logs):\n",
    "    predictions = model.predict(X_test)\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    cm = metrics.confusion_matrix(np.argmax(Y_test, axis=1), predictions)\n",
    "    figure = plot_confusion_matrix(cm, class_names=classes_values)\n",
    "    cm_image = plot_to_image(figure)\n",
    "\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/180\n",
      "92/92 - 0s - loss: 3.0040 - accuracy: 0.1141 - val_loss: 2.4022 - val_accuracy: 0.2595\n",
      "Epoch 2/180\n",
      "92/92 - 0s - loss: 2.3909 - accuracy: 0.2052 - val_loss: 2.1327 - val_accuracy: 0.4348\n",
      "Epoch 3/180\n",
      "92/92 - 0s - loss: 2.0137 - accuracy: 0.3173 - val_loss: 1.6509 - val_accuracy: 0.5761\n",
      "Epoch 4/180\n",
      "92/92 - 0s - loss: 1.6915 - accuracy: 0.4297 - val_loss: 1.2916 - val_accuracy: 0.7133\n",
      "Epoch 5/180\n",
      "92/92 - 0s - loss: 1.4124 - accuracy: 0.5394 - val_loss: 1.0187 - val_accuracy: 0.7785\n",
      "Epoch 6/180\n",
      "92/92 - 0s - loss: 1.2334 - accuracy: 0.6101 - val_loss: 0.8535 - val_accuracy: 0.8261\n",
      "Epoch 7/180\n",
      "92/92 - 0s - loss: 1.0842 - accuracy: 0.6467 - val_loss: 0.7131 - val_accuracy: 0.8601\n",
      "Epoch 8/180\n",
      "92/92 - 0s - loss: 0.9515 - accuracy: 0.6980 - val_loss: 0.6004 - val_accuracy: 0.8804\n",
      "Epoch 9/180\n",
      "92/92 - 0s - loss: 0.8749 - accuracy: 0.7259 - val_loss: 0.5189 - val_accuracy: 0.9022\n",
      "Epoch 10/180\n",
      "92/92 - 0s - loss: 0.8253 - accuracy: 0.7381 - val_loss: 0.4775 - val_accuracy: 0.9008\n",
      "Epoch 11/180\n",
      "92/92 - 0s - loss: 0.7445 - accuracy: 0.7568 - val_loss: 0.4196 - val_accuracy: 0.9158\n",
      "Epoch 12/180\n",
      "92/92 - 0s - loss: 0.7074 - accuracy: 0.7792 - val_loss: 0.3980 - val_accuracy: 0.9171\n",
      "Epoch 13/180\n",
      "92/92 - 0s - loss: 0.6426 - accuracy: 0.7989 - val_loss: 0.3545 - val_accuracy: 0.9375\n",
      "Epoch 14/180\n",
      "92/92 - 0s - loss: 0.6085 - accuracy: 0.8111 - val_loss: 0.3347 - val_accuracy: 0.9389\n",
      "Epoch 15/180\n",
      "92/92 - 0s - loss: 0.5794 - accuracy: 0.8224 - val_loss: 0.3103 - val_accuracy: 0.9389\n",
      "Epoch 16/180\n",
      "92/92 - 0s - loss: 0.5354 - accuracy: 0.8342 - val_loss: 0.2990 - val_accuracy: 0.9402\n",
      "Epoch 17/180\n",
      "92/92 - 0s - loss: 0.5308 - accuracy: 0.8404 - val_loss: 0.2841 - val_accuracy: 0.9457\n",
      "Epoch 18/180\n",
      "92/92 - 0s - loss: 0.4772 - accuracy: 0.8590 - val_loss: 0.2569 - val_accuracy: 0.9484\n",
      "Epoch 19/180\n",
      "92/92 - 0s - loss: 0.4905 - accuracy: 0.8478 - val_loss: 0.2604 - val_accuracy: 0.9416\n",
      "Epoch 20/180\n",
      "92/92 - 0s - loss: 0.4756 - accuracy: 0.8573 - val_loss: 0.2485 - val_accuracy: 0.9457\n",
      "Epoch 21/180\n",
      "92/92 - 0s - loss: 0.4667 - accuracy: 0.8655 - val_loss: 0.2325 - val_accuracy: 0.9511\n",
      "Epoch 22/180\n",
      "92/92 - 0s - loss: 0.4544 - accuracy: 0.8584 - val_loss: 0.2270 - val_accuracy: 0.9524\n",
      "Epoch 23/180\n",
      "92/92 - 0s - loss: 0.4199 - accuracy: 0.8692 - val_loss: 0.2170 - val_accuracy: 0.9511\n",
      "Epoch 24/180\n",
      "92/92 - 0s - loss: 0.3951 - accuracy: 0.8764 - val_loss: 0.2114 - val_accuracy: 0.9592\n",
      "Epoch 25/180\n",
      "92/92 - 0s - loss: 0.4080 - accuracy: 0.8798 - val_loss: 0.2094 - val_accuracy: 0.9552\n",
      "Epoch 26/180\n",
      "92/92 - 0s - loss: 0.4117 - accuracy: 0.8713 - val_loss: 0.1968 - val_accuracy: 0.9592\n",
      "Epoch 27/180\n",
      "92/92 - 0s - loss: 0.3731 - accuracy: 0.8842 - val_loss: 0.1917 - val_accuracy: 0.9565\n",
      "Epoch 28/180\n",
      "92/92 - 0s - loss: 0.3705 - accuracy: 0.8832 - val_loss: 0.1891 - val_accuracy: 0.9606\n",
      "Epoch 29/180\n",
      "92/92 - 0s - loss: 0.3600 - accuracy: 0.8845 - val_loss: 0.1879 - val_accuracy: 0.9579\n",
      "Epoch 30/180\n",
      "92/92 - 0s - loss: 0.3705 - accuracy: 0.8869 - val_loss: 0.1788 - val_accuracy: 0.9579\n",
      "Epoch 31/180\n",
      "92/92 - 0s - loss: 0.3735 - accuracy: 0.8787 - val_loss: 0.1802 - val_accuracy: 0.9552\n",
      "Epoch 32/180\n",
      "92/92 - 0s - loss: 0.3436 - accuracy: 0.8882 - val_loss: 0.1719 - val_accuracy: 0.9633\n",
      "Epoch 33/180\n",
      "92/92 - 0s - loss: 0.3358 - accuracy: 0.8967 - val_loss: 0.1703 - val_accuracy: 0.9538\n",
      "Epoch 34/180\n",
      "92/92 - 0s - loss: 0.3387 - accuracy: 0.8950 - val_loss: 0.1637 - val_accuracy: 0.9606\n",
      "Epoch 35/180\n",
      "92/92 - 0s - loss: 0.3433 - accuracy: 0.8869 - val_loss: 0.1596 - val_accuracy: 0.9633\n",
      "Epoch 36/180\n",
      "92/92 - 0s - loss: 0.3328 - accuracy: 0.8981 - val_loss: 0.1587 - val_accuracy: 0.9647\n",
      "Epoch 37/180\n",
      "92/92 - 0s - loss: 0.3246 - accuracy: 0.8978 - val_loss: 0.1556 - val_accuracy: 0.9620\n",
      "Epoch 38/180\n",
      "92/92 - 0s - loss: 0.3251 - accuracy: 0.8984 - val_loss: 0.1509 - val_accuracy: 0.9633\n",
      "Epoch 39/180\n",
      "92/92 - 0s - loss: 0.3123 - accuracy: 0.9032 - val_loss: 0.1526 - val_accuracy: 0.9660\n",
      "Epoch 40/180\n",
      "92/92 - 0s - loss: 0.3038 - accuracy: 0.9056 - val_loss: 0.1481 - val_accuracy: 0.9647\n",
      "Epoch 41/180\n",
      "92/92 - 0s - loss: 0.3040 - accuracy: 0.9039 - val_loss: 0.1485 - val_accuracy: 0.9647\n",
      "Epoch 42/180\n",
      "92/92 - 0s - loss: 0.3090 - accuracy: 0.9039 - val_loss: 0.1471 - val_accuracy: 0.9674\n",
      "Epoch 43/180\n",
      "92/92 - 0s - loss: 0.3059 - accuracy: 0.9018 - val_loss: 0.1415 - val_accuracy: 0.9674\n",
      "Epoch 44/180\n",
      "92/92 - 0s - loss: 0.3009 - accuracy: 0.9032 - val_loss: 0.1379 - val_accuracy: 0.9647\n",
      "Epoch 45/180\n",
      "92/92 - 0s - loss: 0.3031 - accuracy: 0.9079 - val_loss: 0.1405 - val_accuracy: 0.9701\n",
      "Epoch 46/180\n",
      "92/92 - 0s - loss: 0.2842 - accuracy: 0.9147 - val_loss: 0.1391 - val_accuracy: 0.9688\n",
      "Epoch 47/180\n",
      "92/92 - 0s - loss: 0.2830 - accuracy: 0.9127 - val_loss: 0.1329 - val_accuracy: 0.9701\n",
      "Epoch 48/180\n",
      "92/92 - 0s - loss: 0.3048 - accuracy: 0.9052 - val_loss: 0.1394 - val_accuracy: 0.9674\n",
      "Epoch 49/180\n",
      "92/92 - 0s - loss: 0.2687 - accuracy: 0.9198 - val_loss: 0.1295 - val_accuracy: 0.9742\n",
      "Epoch 50/180\n",
      "92/92 - 0s - loss: 0.2770 - accuracy: 0.9164 - val_loss: 0.1349 - val_accuracy: 0.9701\n",
      "Epoch 51/180\n",
      "92/92 - 0s - loss: 0.2780 - accuracy: 0.9192 - val_loss: 0.1327 - val_accuracy: 0.9701\n",
      "Epoch 52/180\n",
      "92/92 - 0s - loss: 0.2758 - accuracy: 0.9117 - val_loss: 0.1285 - val_accuracy: 0.9688\n",
      "Epoch 53/180\n",
      "92/92 - 0s - loss: 0.2770 - accuracy: 0.9175 - val_loss: 0.1257 - val_accuracy: 0.9688\n",
      "Epoch 54/180\n",
      "92/92 - 0s - loss: 0.2580 - accuracy: 0.9130 - val_loss: 0.1212 - val_accuracy: 0.9715\n",
      "Epoch 55/180\n",
      "92/92 - 0s - loss: 0.2620 - accuracy: 0.9195 - val_loss: 0.1226 - val_accuracy: 0.9701\n",
      "Epoch 56/180\n",
      "92/92 - 0s - loss: 0.2815 - accuracy: 0.9076 - val_loss: 0.1207 - val_accuracy: 0.9769\n",
      "Epoch 57/180\n",
      "92/92 - 0s - loss: 0.2661 - accuracy: 0.9185 - val_loss: 0.1264 - val_accuracy: 0.9755\n",
      "Epoch 58/180\n",
      "92/92 - 0s - loss: 0.2404 - accuracy: 0.9195 - val_loss: 0.1267 - val_accuracy: 0.9728\n",
      "Epoch 59/180\n",
      "92/92 - 0s - loss: 0.2606 - accuracy: 0.9185 - val_loss: 0.1233 - val_accuracy: 0.9701\n",
      "Epoch 60/180\n",
      "92/92 - 0s - loss: 0.2572 - accuracy: 0.9168 - val_loss: 0.1164 - val_accuracy: 0.9715\n",
      "Epoch 61/180\n",
      "92/92 - 0s - loss: 0.2515 - accuracy: 0.9161 - val_loss: 0.1151 - val_accuracy: 0.9715\n",
      "Epoch 62/180\n",
      "92/92 - 0s - loss: 0.2260 - accuracy: 0.9243 - val_loss: 0.1132 - val_accuracy: 0.9715\n",
      "Epoch 63/180\n",
      "92/92 - 0s - loss: 0.2399 - accuracy: 0.9260 - val_loss: 0.1104 - val_accuracy: 0.9728\n",
      "Epoch 64/180\n",
      "92/92 - 0s - loss: 0.2343 - accuracy: 0.9219 - val_loss: 0.1103 - val_accuracy: 0.9742\n",
      "Epoch 65/180\n",
      "92/92 - 0s - loss: 0.2279 - accuracy: 0.9276 - val_loss: 0.1088 - val_accuracy: 0.9715\n",
      "Epoch 66/180\n",
      "92/92 - 0s - loss: 0.2686 - accuracy: 0.9158 - val_loss: 0.1135 - val_accuracy: 0.9728\n",
      "Epoch 67/180\n",
      "92/92 - 0s - loss: 0.2337 - accuracy: 0.9236 - val_loss: 0.1123 - val_accuracy: 0.9728\n",
      "Epoch 68/180\n",
      "92/92 - 0s - loss: 0.2333 - accuracy: 0.9222 - val_loss: 0.1070 - val_accuracy: 0.9742\n",
      "Epoch 69/180\n",
      "92/92 - 0s - loss: 0.2450 - accuracy: 0.9246 - val_loss: 0.1089 - val_accuracy: 0.9742\n",
      "Epoch 70/180\n",
      "92/92 - 0s - loss: 0.2264 - accuracy: 0.9232 - val_loss: 0.1090 - val_accuracy: 0.9755\n",
      "Epoch 71/180\n",
      "92/92 - 0s - loss: 0.2338 - accuracy: 0.9307 - val_loss: 0.1056 - val_accuracy: 0.9742\n",
      "Epoch 72/180\n",
      "92/92 - 0s - loss: 0.2354 - accuracy: 0.9198 - val_loss: 0.1063 - val_accuracy: 0.9742\n",
      "Epoch 73/180\n",
      "92/92 - 0s - loss: 0.2419 - accuracy: 0.9236 - val_loss: 0.1025 - val_accuracy: 0.9755\n",
      "Epoch 74/180\n",
      "92/92 - 0s - loss: 0.2328 - accuracy: 0.9276 - val_loss: 0.1044 - val_accuracy: 0.9783\n",
      "Epoch 75/180\n",
      "92/92 - 0s - loss: 0.2359 - accuracy: 0.9219 - val_loss: 0.1037 - val_accuracy: 0.9769\n",
      "Epoch 76/180\n",
      "92/92 - 0s - loss: 0.2319 - accuracy: 0.9249 - val_loss: 0.1019 - val_accuracy: 0.9796\n",
      "Epoch 77/180\n",
      "92/92 - 0s - loss: 0.2062 - accuracy: 0.9355 - val_loss: 0.1036 - val_accuracy: 0.9755\n",
      "Epoch 78/180\n",
      "92/92 - 0s - loss: 0.2258 - accuracy: 0.9290 - val_loss: 0.1000 - val_accuracy: 0.9769\n",
      "Epoch 79/180\n",
      "92/92 - 0s - loss: 0.2436 - accuracy: 0.9276 - val_loss: 0.1031 - val_accuracy: 0.9755\n",
      "Epoch 80/180\n",
      "92/92 - 0s - loss: 0.2324 - accuracy: 0.9205 - val_loss: 0.1018 - val_accuracy: 0.9783\n",
      "Epoch 81/180\n",
      "92/92 - 0s - loss: 0.2172 - accuracy: 0.9293 - val_loss: 0.0964 - val_accuracy: 0.9796\n",
      "Epoch 82/180\n",
      "92/92 - 0s - loss: 0.2214 - accuracy: 0.9314 - val_loss: 0.0990 - val_accuracy: 0.9796\n",
      "Epoch 83/180\n",
      "92/92 - 0s - loss: 0.2044 - accuracy: 0.9317 - val_loss: 0.0976 - val_accuracy: 0.9810\n",
      "Epoch 84/180\n",
      "92/92 - 0s - loss: 0.2145 - accuracy: 0.9307 - val_loss: 0.0997 - val_accuracy: 0.9796\n",
      "Epoch 85/180\n",
      "92/92 - 0s - loss: 0.2178 - accuracy: 0.9253 - val_loss: 0.0999 - val_accuracy: 0.9755\n",
      "Epoch 86/180\n",
      "92/92 - 0s - loss: 0.2370 - accuracy: 0.9198 - val_loss: 0.0958 - val_accuracy: 0.9823\n",
      "Epoch 87/180\n",
      "92/92 - 0s - loss: 0.2163 - accuracy: 0.9310 - val_loss: 0.0933 - val_accuracy: 0.9810\n",
      "Epoch 88/180\n",
      "92/92 - 0s - loss: 0.2177 - accuracy: 0.9297 - val_loss: 0.0950 - val_accuracy: 0.9783\n",
      "Epoch 89/180\n",
      "92/92 - 0s - loss: 0.1812 - accuracy: 0.9440 - val_loss: 0.0910 - val_accuracy: 0.9783\n",
      "Epoch 90/180\n",
      "92/92 - 0s - loss: 0.1958 - accuracy: 0.9382 - val_loss: 0.0935 - val_accuracy: 0.9769\n",
      "Epoch 91/180\n",
      "92/92 - 0s - loss: 0.2049 - accuracy: 0.9317 - val_loss: 0.0941 - val_accuracy: 0.9769\n",
      "Epoch 92/180\n",
      "92/92 - 0s - loss: 0.2186 - accuracy: 0.9249 - val_loss: 0.0912 - val_accuracy: 0.9769\n",
      "Epoch 93/180\n",
      "92/92 - 0s - loss: 0.2020 - accuracy: 0.9334 - val_loss: 0.0933 - val_accuracy: 0.9783\n",
      "Epoch 94/180\n",
      "92/92 - 0s - loss: 0.2069 - accuracy: 0.9317 - val_loss: 0.0923 - val_accuracy: 0.9796\n",
      "Epoch 95/180\n",
      "92/92 - 0s - loss: 0.2074 - accuracy: 0.9324 - val_loss: 0.0931 - val_accuracy: 0.9796\n",
      "Epoch 96/180\n",
      "92/92 - 0s - loss: 0.2036 - accuracy: 0.9307 - val_loss: 0.0966 - val_accuracy: 0.9823\n",
      "Epoch 97/180\n",
      "92/92 - 0s - loss: 0.1826 - accuracy: 0.9402 - val_loss: 0.0869 - val_accuracy: 0.9796\n",
      "Epoch 98/180\n",
      "92/92 - 0s - loss: 0.1958 - accuracy: 0.9416 - val_loss: 0.0894 - val_accuracy: 0.9796\n",
      "Epoch 99/180\n",
      "92/92 - 0s - loss: 0.1912 - accuracy: 0.9372 - val_loss: 0.0935 - val_accuracy: 0.9796\n",
      "Epoch 100/180\n",
      "92/92 - 0s - loss: 0.2220 - accuracy: 0.9287 - val_loss: 0.0929 - val_accuracy: 0.9823\n",
      "Epoch 101/180\n",
      "92/92 - 0s - loss: 0.2046 - accuracy: 0.9287 - val_loss: 0.0922 - val_accuracy: 0.9823\n",
      "Epoch 102/180\n",
      "92/92 - 0s - loss: 0.2200 - accuracy: 0.9297 - val_loss: 0.0960 - val_accuracy: 0.9796\n",
      "Epoch 103/180\n",
      "92/92 - 0s - loss: 0.1930 - accuracy: 0.9348 - val_loss: 0.0962 - val_accuracy: 0.9783\n",
      "Epoch 104/180\n",
      "92/92 - 0s - loss: 0.1940 - accuracy: 0.9389 - val_loss: 0.0917 - val_accuracy: 0.9837\n",
      "Epoch 105/180\n",
      "92/92 - 0s - loss: 0.1938 - accuracy: 0.9348 - val_loss: 0.0920 - val_accuracy: 0.9823\n",
      "Epoch 106/180\n",
      "92/92 - 0s - loss: 0.2004 - accuracy: 0.9361 - val_loss: 0.0938 - val_accuracy: 0.9837\n",
      "Epoch 107/180\n",
      "92/92 - 0s - loss: 0.1882 - accuracy: 0.9412 - val_loss: 0.0917 - val_accuracy: 0.9796\n",
      "Epoch 108/180\n",
      "92/92 - 0s - loss: 0.1938 - accuracy: 0.9314 - val_loss: 0.0958 - val_accuracy: 0.9796\n",
      "Epoch 109/180\n",
      "92/92 - 0s - loss: 0.1945 - accuracy: 0.9385 - val_loss: 0.0961 - val_accuracy: 0.9796\n",
      "Epoch 110/180\n",
      "92/92 - 0s - loss: 0.2080 - accuracy: 0.9402 - val_loss: 0.0974 - val_accuracy: 0.9810\n",
      "Epoch 111/180\n",
      "92/92 - 0s - loss: 0.1898 - accuracy: 0.9372 - val_loss: 0.0992 - val_accuracy: 0.9769\n",
      "Epoch 112/180\n",
      "92/92 - 0s - loss: 0.2004 - accuracy: 0.9372 - val_loss: 0.1003 - val_accuracy: 0.9769\n",
      "Epoch 113/180\n",
      "92/92 - 0s - loss: 0.1965 - accuracy: 0.9365 - val_loss: 0.0952 - val_accuracy: 0.9769\n",
      "Epoch 114/180\n",
      "92/92 - 0s - loss: 0.1882 - accuracy: 0.9429 - val_loss: 0.0930 - val_accuracy: 0.9810\n",
      "Epoch 115/180\n",
      "92/92 - 0s - loss: 0.1899 - accuracy: 0.9378 - val_loss: 0.0980 - val_accuracy: 0.9769\n",
      "Epoch 116/180\n",
      "92/92 - 0s - loss: 0.1770 - accuracy: 0.9429 - val_loss: 0.0956 - val_accuracy: 0.9796\n",
      "Epoch 117/180\n",
      "92/92 - 0s - loss: 0.2010 - accuracy: 0.9409 - val_loss: 0.0956 - val_accuracy: 0.9796\n",
      "Epoch 118/180\n",
      "92/92 - 0s - loss: 0.1805 - accuracy: 0.9412 - val_loss: 0.0944 - val_accuracy: 0.9796\n",
      "Epoch 119/180\n",
      "92/92 - 0s - loss: 0.1888 - accuracy: 0.9372 - val_loss: 0.0900 - val_accuracy: 0.9810\n",
      "Epoch 120/180\n",
      "92/92 - 0s - loss: 0.1770 - accuracy: 0.9412 - val_loss: 0.0922 - val_accuracy: 0.9796\n",
      "Epoch 121/180\n",
      "92/92 - 0s - loss: 0.1819 - accuracy: 0.9409 - val_loss: 0.0890 - val_accuracy: 0.9810\n",
      "Epoch 122/180\n",
      "92/92 - 0s - loss: 0.1883 - accuracy: 0.9385 - val_loss: 0.0915 - val_accuracy: 0.9769\n",
      "Epoch 123/180\n",
      "92/92 - 0s - loss: 0.1933 - accuracy: 0.9389 - val_loss: 0.0929 - val_accuracy: 0.9796\n",
      "Epoch 124/180\n",
      "92/92 - 0s - loss: 0.1834 - accuracy: 0.9412 - val_loss: 0.0914 - val_accuracy: 0.9823\n",
      "Epoch 125/180\n",
      "92/92 - 0s - loss: 0.1849 - accuracy: 0.9412 - val_loss: 0.0881 - val_accuracy: 0.9837\n",
      "Epoch 126/180\n",
      "92/92 - 0s - loss: 0.1831 - accuracy: 0.9395 - val_loss: 0.0878 - val_accuracy: 0.9796\n",
      "Epoch 127/180\n",
      "92/92 - 0s - loss: 0.1831 - accuracy: 0.9406 - val_loss: 0.0884 - val_accuracy: 0.9810\n",
      "Epoch 128/180\n",
      "92/92 - 0s - loss: 0.1723 - accuracy: 0.9406 - val_loss: 0.0855 - val_accuracy: 0.9823\n",
      "Epoch 129/180\n",
      "92/92 - 0s - loss: 0.1825 - accuracy: 0.9375 - val_loss: 0.0907 - val_accuracy: 0.9796\n",
      "Epoch 130/180\n",
      "92/92 - 0s - loss: 0.1743 - accuracy: 0.9429 - val_loss: 0.0898 - val_accuracy: 0.9823\n",
      "Epoch 131/180\n",
      "92/92 - 0s - loss: 0.1885 - accuracy: 0.9406 - val_loss: 0.0899 - val_accuracy: 0.9810\n",
      "Epoch 132/180\n",
      "92/92 - 0s - loss: 0.1831 - accuracy: 0.9375 - val_loss: 0.0864 - val_accuracy: 0.9823\n",
      "Epoch 133/180\n",
      "92/92 - 0s - loss: 0.1803 - accuracy: 0.9389 - val_loss: 0.0921 - val_accuracy: 0.9783\n",
      "Epoch 134/180\n",
      "92/92 - 0s - loss: 0.1660 - accuracy: 0.9477 - val_loss: 0.0928 - val_accuracy: 0.9796\n",
      "Epoch 135/180\n",
      "92/92 - 0s - loss: 0.1800 - accuracy: 0.9389 - val_loss: 0.0904 - val_accuracy: 0.9769\n",
      "Epoch 136/180\n",
      "92/92 - 0s - loss: 0.1718 - accuracy: 0.9446 - val_loss: 0.0886 - val_accuracy: 0.9769\n",
      "Epoch 137/180\n",
      "92/92 - 0s - loss: 0.1795 - accuracy: 0.9453 - val_loss: 0.0846 - val_accuracy: 0.9823\n",
      "Epoch 138/180\n",
      "92/92 - 0s - loss: 0.1603 - accuracy: 0.9429 - val_loss: 0.0842 - val_accuracy: 0.9823\n",
      "Epoch 139/180\n",
      "92/92 - 0s - loss: 0.1712 - accuracy: 0.9426 - val_loss: 0.0857 - val_accuracy: 0.9823\n",
      "Epoch 140/180\n",
      "92/92 - 0s - loss: 0.1742 - accuracy: 0.9443 - val_loss: 0.0907 - val_accuracy: 0.9823\n",
      "Epoch 141/180\n",
      "92/92 - 0s - loss: 0.1700 - accuracy: 0.9395 - val_loss: 0.0889 - val_accuracy: 0.9823\n",
      "Epoch 142/180\n",
      "92/92 - 0s - loss: 0.1871 - accuracy: 0.9389 - val_loss: 0.0868 - val_accuracy: 0.9837\n",
      "Epoch 143/180\n",
      "92/92 - 0s - loss: 0.1716 - accuracy: 0.9419 - val_loss: 0.0894 - val_accuracy: 0.9810\n",
      "Epoch 144/180\n",
      "92/92 - 0s - loss: 0.1680 - accuracy: 0.9375 - val_loss: 0.0885 - val_accuracy: 0.9796\n",
      "Epoch 145/180\n",
      "92/92 - 0s - loss: 0.1674 - accuracy: 0.9412 - val_loss: 0.0877 - val_accuracy: 0.9823\n",
      "Epoch 146/180\n",
      "92/92 - 0s - loss: 0.1784 - accuracy: 0.9412 - val_loss: 0.0897 - val_accuracy: 0.9823\n",
      "Epoch 147/180\n",
      "92/92 - 0s - loss: 0.1501 - accuracy: 0.9504 - val_loss: 0.0867 - val_accuracy: 0.9823\n",
      "Epoch 148/180\n",
      "92/92 - 0s - loss: 0.1663 - accuracy: 0.9504 - val_loss: 0.0895 - val_accuracy: 0.9851\n",
      "Epoch 149/180\n",
      "92/92 - 0s - loss: 0.1581 - accuracy: 0.9487 - val_loss: 0.0885 - val_accuracy: 0.9810\n",
      "Epoch 150/180\n",
      "92/92 - 0s - loss: 0.1742 - accuracy: 0.9419 - val_loss: 0.0896 - val_accuracy: 0.9851\n",
      "Epoch 151/180\n",
      "92/92 - 0s - loss: 0.1568 - accuracy: 0.9490 - val_loss: 0.0872 - val_accuracy: 0.9823\n",
      "Epoch 152/180\n",
      "92/92 - 0s - loss: 0.1597 - accuracy: 0.9474 - val_loss: 0.0889 - val_accuracy: 0.9823\n",
      "Epoch 153/180\n",
      "92/92 - 0s - loss: 0.1698 - accuracy: 0.9474 - val_loss: 0.0874 - val_accuracy: 0.9837\n",
      "Epoch 154/180\n",
      "92/92 - 0s - loss: 0.1779 - accuracy: 0.9395 - val_loss: 0.0950 - val_accuracy: 0.9783\n",
      "Epoch 155/180\n",
      "92/92 - 0s - loss: 0.1603 - accuracy: 0.9507 - val_loss: 0.0911 - val_accuracy: 0.9823\n",
      "Epoch 156/180\n",
      "92/92 - 0s - loss: 0.1956 - accuracy: 0.9378 - val_loss: 0.0877 - val_accuracy: 0.9851\n",
      "Epoch 157/180\n",
      "92/92 - 0s - loss: 0.1682 - accuracy: 0.9453 - val_loss: 0.0885 - val_accuracy: 0.9837\n",
      "Epoch 158/180\n",
      "92/92 - 0s - loss: 0.1680 - accuracy: 0.9436 - val_loss: 0.0903 - val_accuracy: 0.9837\n",
      "Epoch 159/180\n",
      "92/92 - 0s - loss: 0.1676 - accuracy: 0.9467 - val_loss: 0.0848 - val_accuracy: 0.9864\n",
      "Epoch 160/180\n",
      "92/92 - 0s - loss: 0.1605 - accuracy: 0.9409 - val_loss: 0.0887 - val_accuracy: 0.9851\n",
      "Epoch 161/180\n",
      "92/92 - 0s - loss: 0.1569 - accuracy: 0.9460 - val_loss: 0.0883 - val_accuracy: 0.9837\n",
      "Epoch 162/180\n",
      "92/92 - 0s - loss: 0.1715 - accuracy: 0.9344 - val_loss: 0.0876 - val_accuracy: 0.9837\n",
      "Epoch 163/180\n",
      "92/92 - 0s - loss: 0.1622 - accuracy: 0.9474 - val_loss: 0.0896 - val_accuracy: 0.9837\n",
      "Epoch 164/180\n",
      "92/92 - 0s - loss: 0.1693 - accuracy: 0.9409 - val_loss: 0.0940 - val_accuracy: 0.9823\n",
      "Epoch 165/180\n",
      "92/92 - 0s - loss: 0.1649 - accuracy: 0.9412 - val_loss: 0.0925 - val_accuracy: 0.9810\n",
      "Epoch 166/180\n",
      "92/92 - 0s - loss: 0.1826 - accuracy: 0.9351 - val_loss: 0.0889 - val_accuracy: 0.9823\n",
      "Epoch 167/180\n",
      "92/92 - 0s - loss: 0.1500 - accuracy: 0.9507 - val_loss: 0.0912 - val_accuracy: 0.9810\n",
      "Epoch 168/180\n",
      "92/92 - 0s - loss: 0.1674 - accuracy: 0.9423 - val_loss: 0.0868 - val_accuracy: 0.9837\n",
      "Epoch 169/180\n",
      "92/92 - 0s - loss: 0.1680 - accuracy: 0.9382 - val_loss: 0.0880 - val_accuracy: 0.9796\n",
      "Epoch 170/180\n",
      "92/92 - 0s - loss: 0.1631 - accuracy: 0.9423 - val_loss: 0.0874 - val_accuracy: 0.9823\n",
      "Epoch 171/180\n",
      "92/92 - 0s - loss: 0.1676 - accuracy: 0.9467 - val_loss: 0.0914 - val_accuracy: 0.9823\n",
      "Epoch 172/180\n",
      "92/92 - 0s - loss: 0.1746 - accuracy: 0.9436 - val_loss: 0.0897 - val_accuracy: 0.9796\n",
      "Epoch 173/180\n",
      "92/92 - 0s - loss: 0.1660 - accuracy: 0.9463 - val_loss: 0.0883 - val_accuracy: 0.9810\n",
      "Epoch 174/180\n",
      "92/92 - 0s - loss: 0.1567 - accuracy: 0.9477 - val_loss: 0.0888 - val_accuracy: 0.9851\n",
      "Epoch 175/180\n",
      "92/92 - 0s - loss: 0.1527 - accuracy: 0.9507 - val_loss: 0.0869 - val_accuracy: 0.9851\n",
      "Epoch 176/180\n",
      "92/92 - 0s - loss: 0.1697 - accuracy: 0.9477 - val_loss: 0.0898 - val_accuracy: 0.9823\n",
      "Epoch 177/180\n",
      "92/92 - 0s - loss: 0.1658 - accuracy: 0.9463 - val_loss: 0.0880 - val_accuracy: 0.9823\n",
      "Epoch 178/180\n",
      "92/92 - 0s - loss: 0.1506 - accuracy: 0.9470 - val_loss: 0.0872 - val_accuracy: 0.9810\n",
      "Epoch 179/180\n",
      "92/92 - 0s - loss: 0.1694 - accuracy: 0.9490 - val_loss: 0.0874 - val_accuracy: 0.9796\n",
      "Epoch 180/180\n",
      "92/92 - 0s - loss: 0.1582 - accuracy: 0.9514 - val_loss: 0.0876 - val_accuracy: 0.9837\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f2228508880>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer, Dropout, Conv1D, Conv2D, Flatten, Reshape, MaxPooling1D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# model architecture\n",
    "model = Sequential()\n",
    "model.add(Reshape((int(input_length / 17), 17), input_shape=(input_length, )))\n",
    "model.add(Conv1D(19, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(35, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(classes, activation='softmax', name='y_pred'))\n",
    "\n",
    "# this controls the learning rate\n",
    "opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "# this controls the batch size, or you can manipulate the tf.data.Dataset objects yourself\n",
    "BATCH_SIZE = 32\n",
    "train_dataset, validation_dataset = set_batch_size(BATCH_SIZE, train_dataset, validation_dataset)\n",
    "\n",
    "# train the neural network\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "   tf.keras.callbacks.TensorBoard(log_dir=logdir,\n",
    "                histogram_freq=1,\n",
    "               write_graph=True,\n",
    "               write_images=True,\n",
    "               update_freq='epoch',\n",
    "               profile_batch=2,\n",
    "               embeddings_freq=1)\n",
    "]\n",
    "\n",
    "#model.fit(train_dataset, epochs=150, validation_data=validation_dataset, verbose=2)\n",
    "model.fit(train_dataset, epochs=180, validation_data=validation_dataset, verbose=2,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./logs/20210221-005235\n",
      "TensorFlow version:  2.3.0\n"
     ]
    }
   ],
   "source": [
    "# Save the model to disk\n",
    "# model.save('saved_model')\n",
    "\n",
    "print(logdir)\n",
    "print(\"TensorFlow version: \", tf.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}